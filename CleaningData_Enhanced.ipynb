{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Enhanced\n",
    "\n",
    "Notebook ini melakukan data cleaning untuk analisis sentimen Twitter tentang sertifikasi halal.\n",
    "\n",
    "**Tahapan Cleaning:**\n",
    "1. Load dan filter data\n",
    "2. Hapus URL\n",
    "3. Hapus Mention (@username)\n",
    "4. Hapus Hashtag (#topic)\n",
    "5. Hapus Emoji dan karakter khusus\n",
    "6. Hapus Angka\n",
    "7. Hapus Whitespace berlebih\n",
    "8. Case folding (lowercase)\n",
    "9. Hapus Duplikat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"data/dataSertifikasiHalal.csv\", index_col=0)\n",
    "print(f\"Jumlah data awal: {len(df)}\")\n",
    "print(f\"Kolom: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilih kolom yang diperlukan dan buat copy untuk menghindari warning\n",
    "df = df[['full_text', 'tweet_url']].copy()\n",
    "print(f\"Kolom yang dipilih: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi-fungsi Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    \"\"\"Menghapus URL dari teks.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+|bit\\.ly/\\S+|t\\.co/\\S+'\n",
    "    return re.sub(url_pattern, '', str(text))\n",
    "\n",
    "\n",
    "def remove_mention(text):\n",
    "    \"\"\"Menghapus mention (@username) dari teks.\"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "    return re.sub(r'@[A-Za-z0-9_]+', '', str(text))\n",
    "\n",
    "\n",
    "def remove_hashtag(text):\n",
    "    \"\"\"Menghapus hashtag (#topic) dari teks.\"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "    return re.sub(r'#[A-Za-z0-9_]+', '', str(text))\n",
    "\n",
    "\n",
    "def remove_emoji(text):\n",
    "    \"\"\"Menghapus emoji dan karakter khusus dari teks.\"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub('', str(text))\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    \"\"\"Menghapus angka dari teks.\"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "    return re.sub(r'\\d+', '', str(text))\n",
    "\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    \"\"\"Menghapus karakter khusus, hanya menyisakan huruf dan spasi.\"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', str(text))\n",
    "\n",
    "\n",
    "def remove_extra_whitespace(text):\n",
    "    \"\"\"Menghapus whitespace berlebih dan trim.\"\"\"\n",
    "    if not text:\n",
    "        return ''\n",
    "    text = re.sub(r'\\s+', ' ', str(text))\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Fungsi utama untuk membersihkan teks.\n",
    "    Menggabungkan semua fungsi cleaning.\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '' or str(text).lower() == 'false':\n",
    "        return ''\n",
    "    \n",
    "    text = str(text)\n",
    "    text = remove_url(text)\n",
    "    text = remove_mention(text)\n",
    "    text = remove_hashtag(text)\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_special_chars(text)\n",
    "    text = remove_extra_whitespace(text)\n",
    "    text = text.lower()  # Case folding di akhir\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fungsi cleaning\n",
    "test_texts = [\n",
    "    \"@user1 Produk ini #halal ðŸ˜Š cek https://example.com nomor 12345!!!\",\n",
    "    \"SERTIFIKASI HALAL sangat PENTING untuk masyarakat Indonesia @MUI\",\n",
    "    \"Batas waktu sertifikasi halal 2026 #UMKM #BPJPH https://t.co/abc123\"\n",
    "]\n",
    "\n",
    "print(\"Test Fungsi Cleaning:\")\n",
    "print(\"=\"*70)\n",
    "for text in test_texts:\n",
    "    result = clean_text(text)\n",
    "    print(f\"\\nBefore: {text}\")\n",
    "    print(f\"After:  {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Cleaning ke Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan teks asli\n",
    "df['original_text'] = df['full_text'].copy()\n",
    "\n",
    "# Apply cleaning\n",
    "print(\"Memulai proses cleaning...\")\n",
    "df['cleaned_text'] = df['full_text'].apply(clean_text)\n",
    "print(\"Cleaning selesai!\")\n",
    "\n",
    "# Preview hasil\n",
    "print(\"\\nContoh hasil cleaning:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\n--- Data {i+1} ---\")\n",
    "    orig = str(df['original_text'].iloc[i])\n",
    "    clean = str(df['cleaned_text'].iloc[i])\n",
    "    print(f\"Original: {orig[:80]}...\" if len(orig) > 80 else f\"Original: {orig}\")\n",
    "    print(f\"Cleaned:  {clean[:80]}...\" if len(clean) > 80 else f\"Cleaned:  {clean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus baris dengan cleaned_text kosong\n",
    "print(f\"Jumlah data sebelum filter kosong: {len(df)}\")\n",
    "df = df[df['cleaned_text'].str.len() > 0]\n",
    "print(f\"Jumlah data setelah filter kosong: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus duplikat berdasarkan cleaned_text\n",
    "print(f\"Jumlah data sebelum hapus duplikat: {len(df)}\")\n",
    "df = df.drop_duplicates(subset=['cleaned_text'])\n",
    "print(f\"Jumlah data setelah hapus duplikat: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Info dataset\n",
    "print(f\"\\nDataset Info:\")\n",
    "print(f\"Jumlah data final: {len(df)}\")\n",
    "print(f\"Kolom: {df.columns.tolist()}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "df[['original_text', 'cleaned_text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat folder data jika belum ada\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Simpan hasil cleaning\n",
    "df.to_csv(\"data/hasil_cleaning.csv\", index=False)\n",
    "print(\"Data berhasil disimpan ke data/hasil_cleaning.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistik Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik panjang teks\n",
    "df['text_length'] = df['cleaned_text'].str.len()\n",
    "df['word_count'] = df['cleaned_text'].str.split().str.len()\n",
    "\n",
    "print(\"Statistik Panjang Teks (karakter):\")\n",
    "print(df['text_length'].describe())\n",
    "\n",
    "print(\"\\nStatistik Jumlah Kata:\")\n",
    "print(df['word_count'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
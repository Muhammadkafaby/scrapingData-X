{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dokumentasi dan Kesimpulan Penelitian\n",
    "\n",
    "## Analisis Sentimen Twitter Mengenai Sertifikasi Halal\n",
    "\n",
    "**Metode:** K-Means Clustering dan Naive Bayes Classification\n",
    "\n",
    "---\n",
    "\n",
    "Notebook ini berisi:\n",
    "1. Ringkasan Statistik Deskriptif\n",
    "2. Parameter yang Digunakan\n",
    "3. Perbandingan Hasil K-Means dan Naive Bayes\n",
    "4. Kelebihan dan Keterbatasan Metode\n",
    "5. Kesimpulan Penelitian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data hasil akhir\n",
    "try:\n",
    "    df = pd.read_csv(\"data/hasil_klasifikasi.csv\")\n",
    "    print(\"Data berhasil dimuat dari hasil_klasifikasi.csv\")\n",
    "except:\n",
    "    try:\n",
    "        df = pd.read_csv(\"data/hasil_clustering.csv\")\n",
    "        print(\"Data berhasil dimuat dari hasil_clustering.csv\")\n",
    "    except:\n",
    "        df = pd.read_csv(\"data/dataSertifikasiHalal.csv\")\n",
    "        print(\"Data berhasil dimuat dari dataSertifikasiHalal.csv\")\n",
    "\n",
    "print(f\"\\nJumlah data: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Ringkasan Statistik Deskriptif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RINGKASAN STATISTIK DESKRIPTIF DATASET\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informasi umum dataset\n",
    "print(\"\\n1.1 INFORMASI UMUM DATASET\")\n",
    "print(\"-\"*40)\n",
    "print(f\"Jumlah total data (tweet): {len(df)}\")\n",
    "print(f\"Jumlah kolom: {len(df.columns)}\")\n",
    "print(f\"Kolom yang tersedia: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribusi sentimen\n",
    "print(\"\\n1.2 DISTRIBUSI SENTIMEN\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "if 'sentiment' in df.columns:\n",
    "    print(\"\\nDistribusi Sentimen (K-Means Clustering):\")\n",
    "    sentiment_dist = df['sentiment'].value_counts()\n",
    "    for sentiment, count in sentiment_dist.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {sentiment.capitalize():10} : {count:5} data ({pct:5.2f}%)\")\n",
    "\n",
    "if 'predicted_sentiment' in df.columns:\n",
    "    print(\"\\nDistribusi Sentimen (Naive Bayes Prediction):\")\n",
    "    pred_dist = df['predicted_sentiment'].value_counts()\n",
    "    for sentiment, count in pred_dist.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {sentiment.capitalize():10} : {count:5} data ({pct:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik panjang teks\n",
    "print(\"\\n1.3 STATISTIK PANJANG TEKS\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "text_col = 'preprocessed_text' if 'preprocessed_text' in df.columns else 'cleaned_text' if 'cleaned_text' in df.columns else 'full_text'\n",
    "\n",
    "if text_col in df.columns:\n",
    "    df['char_count'] = df[text_col].str.len()\n",
    "    df['word_count'] = df[text_col].str.split().str.len()\n",
    "    \n",
    "    print(f\"\\nStatistik Jumlah Karakter ({text_col}):\")\n",
    "    print(f\"  Minimum  : {df['char_count'].min():.0f}\")\n",
    "    print(f\"  Maksimum : {df['char_count'].max():.0f}\")\n",
    "    print(f\"  Rata-rata: {df['char_count'].mean():.2f}\")\n",
    "    print(f\"  Median   : {df['char_count'].median():.0f}\")\n",
    "    print(f\"  Std Dev  : {df['char_count'].std():.2f}\")\n",
    "    \n",
    "    print(f\"\\nStatistik Jumlah Kata ({text_col}):\")\n",
    "    print(f\"  Minimum  : {df['word_count'].min():.0f}\")\n",
    "    print(f\"  Maksimum : {df['word_count'].max():.0f}\")\n",
    "    print(f\"  Rata-rata: {df['word_count'].mean():.2f}\")\n",
    "    print(f\"  Median   : {df['word_count'].median():.0f}\")\n",
    "    print(f\"  Std Dev  : {df['word_count'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik per sentimen\n",
    "print(\"\\n1.4 STATISTIK PER SENTIMEN\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "if 'sentiment' in df.columns and 'word_count' in df.columns:\n",
    "    print(\"\\nRata-rata jumlah kata per sentimen:\")\n",
    "    for sentiment in df['sentiment'].unique():\n",
    "        avg_words = df[df['sentiment'] == sentiment]['word_count'].mean()\n",
    "        print(f\"  {sentiment.capitalize():10} : {avg_words:.2f} kata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Parameter yang Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PARAMETER YANG DIGUNAKAN\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2.1 PARAMETER DATA CLEANING\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "Tahapan cleaning yang dilakukan:\n",
    "  1. Hapus URL (http://, https://, www., bit.ly, t.co)\n",
    "  2. Hapus Mention (@username)\n",
    "  3. Hapus Hashtag (#topic)\n",
    "  4. Hapus Emoji dan karakter Unicode khusus\n",
    "  5. Hapus Angka\n",
    "  6. Hapus Karakter khusus (hanya menyisakan huruf dan spasi)\n",
    "  7. Hapus Whitespace berlebih\n",
    "  8. Hapus Duplikat berdasarkan teks yang sudah dibersihkan\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2.2 PARAMETER TEXT PREPROCESSING\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "Tahapan preprocessing yang dilakukan:\n",
    "  1. Case Folding: Mengubah semua huruf menjadi lowercase\n",
    "  2. Cleaning: Menghapus simbol, angka, dan karakter non-huruf\n",
    "  3. Tokenizing: Memecah teks menjadi kata-kata (token)\n",
    "     - Filter kata dengan panjang <= 2 karakter\n",
    "  4. Stopword Removal: Menghapus kata-kata umum bahasa Indonesia\n",
    "     - Menggunakan daftar stopword kustom (150+ kata)\n",
    "     - Termasuk slang Twitter (yg, dgn, utk, gak, dll)\n",
    "  \n",
    "  CATATAN: Stemming TIDAK digunakan untuk menjaga kata tetap utuh\n",
    "  (contoh: 'sertifikasi' tidak diubah menjadi 'rtifikas')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2.3 PARAMETER TF-IDF VECTORIZATION\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "Parameter TfidfVectorizer:\n",
    "  - max_features: 1000 (membatasi jumlah fitur/kata)\n",
    "  - min_df: 2 (kata minimal muncul di 2 dokumen)\n",
    "  - max_df: 0.95 (kata maksimal muncul di 95% dokumen)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2.4 PARAMETER K-MEANS CLUSTERING\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "Parameter KMeans:\n",
    "  - n_clusters: 3 (positif, negatif, netral)\n",
    "  - random_state: 42 (untuk reprodusibilitas)\n",
    "  - n_init: 10 (jumlah inisialisasi centroid)\n",
    "  - max_iter: 300 (maksimum iterasi)\n",
    "  \n",
    "Metode penentuan k optimal:\n",
    "  - Elbow Method (range k=2 sampai k=10)\n",
    "  - Silhouette Score\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2.5 PARAMETER NAIVE BAYES CLASSIFICATION\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "Parameter MultinomialNB:\n",
    "  - alpha: 1.0 (Laplace smoothing)\n",
    "  \n",
    "Parameter Train-Test Split:\n",
    "  - test_size: 0.2 (20% untuk testing)\n",
    "  - random_state: 42 (untuk reprodusibilitas)\n",
    "  - stratify: y (menjaga proporsi kelas)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Perbandingan Hasil K-Means dan Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PERBANDINGAN HASIL K-MEANS DAN NAIVE BAYES\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sentiment' in df.columns and 'predicted_sentiment' in df.columns:\n",
    "    print(\"\\n3.1 TABEL PERBANDINGAN DISTRIBUSI\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        'K-Means': df['sentiment'].value_counts(),\n",
    "        'Naive Bayes': df['predicted_sentiment'].value_counts()\n",
    "    })\n",
    "    comparison_df['Selisih'] = comparison_df['K-Means'] - comparison_df['Naive Bayes']\n",
    "    print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sentiment' in df.columns and 'predicted_sentiment' in df.columns:\n",
    "    print(\"\\n3.2 KESESUAIAN LABEL\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    # Hitung kesesuaian\n",
    "    match_count = (df['sentiment'] == df['predicted_sentiment']).sum()\n",
    "    mismatch_count = len(df) - match_count\n",
    "    match_pct = match_count / len(df) * 100\n",
    "    \n",
    "    print(f\"Data dengan label sama    : {match_count} ({match_pct:.2f}%)\")\n",
    "    print(f\"Data dengan label berbeda : {mismatch_count} ({100-match_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sentiment' in df.columns and 'predicted_sentiment' in df.columns:\n",
    "    print(\"\\n3.3 CROSS-TABULATION\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    crosstab = pd.crosstab(\n",
    "        df['sentiment'], \n",
    "        df['predicted_sentiment'],\n",
    "        margins=True,\n",
    "        margins_name='Total'\n",
    "    )\n",
    "    print(\"\\nTabel silang K-Means vs Naive Bayes:\")\n",
    "    print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n3.4 ANALISIS KESESUAIAN\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "Interpretasi:\n",
    "- Kesesuaian tinggi menunjukkan bahwa hasil clustering K-Means\n",
    "  dapat digunakan sebagai label yang valid untuk klasifikasi.\n",
    "- Perbedaan label dapat terjadi karena:\n",
    "  1. Ambiguitas teks yang sulit dikategorikan\n",
    "  2. Keterbatasan K-Means dalam menangkap nuansa sentimen\n",
    "  3. Naive Bayes mempelajari pola dari data training\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Kelebihan dan Keterbatasan Metode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"KELEBIHAN DAN KETERBATASAN METODE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4.1 K-MEANS CLUSTERING\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "KELEBIHAN:\n",
    "  ✓ Tidak memerlukan data berlabel (unsupervised)\n",
    "  ✓ Dapat menemukan pola tersembunyi dalam data\n",
    "  ✓ Komputasi relatif cepat untuk dataset besar\n",
    "  ✓ Mudah diimplementasikan dan diinterpretasikan\n",
    "  ✓ Cocok untuk eksplorasi awal data\n",
    "\n",
    "KETERBATASAN:\n",
    "  ✗ Harus menentukan jumlah cluster (k) di awal\n",
    "  ✗ Sensitif terhadap inisialisasi centroid\n",
    "  ✗ Tidak optimal untuk cluster non-spherical\n",
    "  ✗ Memerlukan interpretasi manual untuk labeling sentimen\n",
    "  ✗ Tidak mempertimbangkan urutan kata (bag-of-words)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4.2 NAIVE BAYES CLASSIFICATION\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "KELEBIHAN:\n",
    "  ✓ Cepat dalam training dan prediksi\n",
    "  ✓ Bekerja baik dengan data teks (high-dimensional)\n",
    "  ✓ Tidak memerlukan banyak data training\n",
    "  ✓ Memberikan probabilitas untuk setiap kelas\n",
    "  ✓ Robust terhadap fitur yang tidak relevan\n",
    "\n",
    "KETERBATASAN:\n",
    "  ✗ Asumsi independensi antar fitur (naive)\n",
    "  ✗ Memerlukan data berlabel untuk training\n",
    "  ✗ Kualitas prediksi bergantung pada kualitas label\n",
    "  ✗ Tidak menangkap hubungan antar kata\n",
    "  ✗ Sensitif terhadap ketidakseimbangan kelas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n4.3 TF-IDF VECTORIZATION\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "KELEBIHAN:\n",
    "  ✓ Memberikan bobot lebih pada kata penting\n",
    "  ✓ Mengurangi pengaruh kata umum\n",
    "  ✓ Representasi numerik yang efektif\n",
    "\n",
    "KETERBATASAN:\n",
    "  ✗ Tidak mempertimbangkan urutan kata\n",
    "  ✗ Tidak menangkap makna semantik\n",
    "  ✗ Sparse matrix untuk vocabulary besar\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Kesimpulan Penelitian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"KESIMPULAN PENELITIAN\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentukan sentimen dominan\n",
    "if 'sentiment' in df.columns:\n",
    "    dominant_sentiment = df['sentiment'].value_counts().idxmax()\n",
    "    dominant_count = df['sentiment'].value_counts().max()\n",
    "    dominant_pct = dominant_count / len(df) * 100\n",
    "    \n",
    "    print(f\"\\n5.1 SENTIMEN DOMINAN MASYARAKAT\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"\\nBerdasarkan analisis {len(df)} tweet tentang sertifikasi halal:\")\n",
    "    print(f\"\\nSentimen dominan: {dominant_sentiment.upper()}\")\n",
    "    print(f\"Jumlah: {dominant_count} tweet ({dominant_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n5.2 RINGKASAN TEMUAN\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "if 'sentiment' in df.columns:\n",
    "    sentiment_summary = df['sentiment'].value_counts()\n",
    "    \n",
    "    print(\"\\nDistribusi sentimen masyarakat terhadap sertifikasi halal:\")\n",
    "    for sentiment in ['positif', 'negatif', 'netral']:\n",
    "        if sentiment in sentiment_summary.index:\n",
    "            count = sentiment_summary[sentiment]\n",
    "            pct = count / len(df) * 100\n",
    "            print(f\"  - {sentiment.capitalize():8}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n5.3 INTERPRETASI HASIL\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "Berdasarkan hasil analisis sentimen menggunakan kombinasi metode\n",
    "K-Means Clustering dan Naive Bayes Classification:\n",
    "\n",
    "1. PENDEKATAN HYBRID:\n",
    "   - K-Means digunakan untuk eksplorasi awal dan labeling otomatis\n",
    "   - Naive Bayes digunakan untuk klasifikasi dan validasi\n",
    "   - Kombinasi kedua metode memberikan hasil yang lebih robust\n",
    "\n",
    "2. KUALITAS CLUSTERING:\n",
    "   - Silhouette Score menunjukkan kualitas pemisahan cluster\n",
    "   - Elbow Method membantu menentukan jumlah cluster optimal\n",
    "   - k=3 dipilih untuk merepresentasikan sentimen positif, negatif, netral\n",
    "\n",
    "3. PERFORMA KLASIFIKASI:\n",
    "   - Model Naive Bayes dapat memprediksi sentimen dengan akurasi yang baik\n",
    "   - Kesesuaian dengan label K-Means menunjukkan konsistensi hasil\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n5.4 SARAN UNTUK PENELITIAN SELANJUTNYA\")\n",
    "print(\"-\"*40)\n",
    "print(\"\"\"\n",
    "1. PENINGKATAN PREPROCESSING:\n",
    "   - Menambahkan normalisasi kata tidak baku (slang)\n",
    "   - Menggunakan kamus sentimen bahasa Indonesia\n",
    "   - Menangani negasi (tidak, bukan, jangan)\n",
    "\n",
    "2. METODE ALTERNATIF:\n",
    "   - Mencoba algoritma deep learning (LSTM, BERT)\n",
    "   - Menggunakan word embedding (Word2Vec, FastText)\n",
    "   - Menerapkan ensemble methods\n",
    "\n",
    "3. VALIDASI LEBIH LANJUT:\n",
    "   - Melakukan labeling manual untuk validasi\n",
    "   - Cross-validation untuk evaluasi yang lebih robust\n",
    "   - Analisis error untuk memahami kesalahan prediksi\n",
    "\n",
    "4. EKSPANSI DATA:\n",
    "   - Mengumpulkan data dari periode waktu yang lebih panjang\n",
    "   - Menambahkan data dari platform media sosial lain\n",
    "   - Mempertimbangkan konteks temporal (tren waktu)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ringkasan Akhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RINGKASAN AKHIR PENELITIAN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "Judul: Analisis Sentimen Twitter Mengenai Sertifikasi Halal\n",
    "       Menggunakan K-Means Clustering dan Naive Bayes Classification\n",
    "\n",
    "Dataset:\n",
    "  - Sumber: Twitter\n",
    "  - Jumlah data: {len(df)} tweet\n",
    "  - Topik: Sertifikasi Halal di Indonesia\n",
    "\n",
    "Metodologi:\n",
    "  1. Data Collection (Scraping)\n",
    "  2. Data Cleaning\n",
    "  3. Text Preprocessing\n",
    "  4. Feature Extraction (TF-IDF)\n",
    "  5. Clustering (K-Means)\n",
    "  6. Classification (Naive Bayes)\n",
    "  7. Visualisasi dan Evaluasi\n",
    "\n",
    "Hasil:\n",
    "  - Sentimen berhasil diklasifikasikan ke dalam 3 kategori\n",
    "  - Model dapat digunakan untuk prediksi sentimen baru\n",
    "  - Visualisasi membantu interpretasi hasil\n",
    "\"\"\")\n",
    "\n",
    "if 'sentiment' in df.columns:\n",
    "    print(\"Distribusi Sentimen Final:\")\n",
    "    for sentiment, count in df['sentiment'].value_counts().items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  - {sentiment.capitalize():8}: {count:5} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
